{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6919c23-b59c-47c7-ae91-963310e3c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-hr HR [HR ...]]\n",
      "                             [-c COUNTRATE [COUNTRATE ...]] [-i [INPUT_FILE]]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/x1/.local/share/jupyter/runtime/kernel-83256d53-e047-42f6-87f2-fdc2679b3baf.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x1/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3348: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "def readPCCURVE(file=\"PCCURVE.qdp\", minExposure=0, minSigma=0, minSNR=0):\n",
    "    \"\"\"Read PCCURVE from Swift data pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file: str, optional\n",
    "            The file to be read. Default is PCCURVE.qdp\n",
    "        minExposure : float, optional\n",
    "            Minimum exposure to consider\n",
    "        minSigma : float, optional\n",
    "            Minimum Sigma to consider.\n",
    "        minSNR: float, optional\n",
    "            Minimum SNR to consider.\n",
    "        \"\"\"\n",
    "    print(\"Reading data from %s\" % file)\n",
    "    try:\n",
    "        data = np.genfromtxt(\"%s\" % file, names=True, delimiter=\"\\t\", skip_header=2, comments=\"!\", dtype=(\"f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, i8, f8, f8, f8, f8, U30\"))\n",
    "    except ValueError:\n",
    "        data = np.genfromtxt(\"%s\" % file, names=True, delimiter=\"\\t\", skip_header=2, comments=\"!\", dtype=(\"f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, i8, f8, f8, f8, f8\"))\n",
    "    filtered_data = data[(data[\"Exposure\"] > minExposure) & (data[\"SNR\"] > minSNR) & (data[\"Sigma\"] > minSigma)]\n",
    "    filtered_obs = len(data) - len(filtered_data)\n",
    "    print(\"Filtered %d datapoints by minSNR = %d\" % (filtered_obs, minSNR))\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def readPCHR(file=\"PCHR.qdp\", minSoftSig=0, minHardSig=0, reject_errors=True, minExposure=0):\n",
    "    \"\"\"Read PCHR from Swift data pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file: str, optional\n",
    "            The file to be read. Default is PCHR.qdp\n",
    "        minSoftSig : float, optional\n",
    "            Minimum soft signal to filer. Default is 0.\n",
    "        minHardSig : float, optional\n",
    "            Minimum hard signal to filer. Default is 0.\n",
    "        reject_errors : boolean, optional\n",
    "            Whether to reject data points with errors higher than the data point value. Default is True.\n",
    "        \"\"\"\n",
    "    print(\"Reading %s data\" % file)\n",
    "    try:\n",
    "        data = np.genfromtxt(\"%s\" % file, names=True, delimiter=\"\\t\", skip_header=2, comments=\"!\", dtype=(\"f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, U30\"))\n",
    "    except ValueError:\n",
    "        data = np.genfromtxt(\"%s\" % file, names=True, delimiter=\"\\t\", skip_header=2, comments=\"!\", dtype=(\"f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8\"))\n",
    "    if reject_errors is True:\n",
    "        filtered_data = data[(~np.isnan(data[\"HR\"])) & (data[\"HR\"] > 0) & (data[\"SoftSig\"] > minSoftSig) & (data[\"HardSig\"] > minHardSig) & (data[\"HRerr\"] < data[\"HR\"]) & (data[\"Exposure\"] > minExposure)]\n",
    "    else:\n",
    "        filtered_data = data[(~np.isnan(data[\"HR\"])) & (data[\"HR\"] > 0) & (data[\"SoftSig\"] > minSoftSig) & (data[\"HardSig\"] > minHardSig) & (data[\"Exposure\"] > minExposure)]\n",
    "    print(\"Filtered %d datapoints\" % (len(data) - len(filtered_data)))\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "ap = argparse.ArgumentParser(description='Cluster data points based on HR and count rate')\n",
    "ap.add_argument(\"-hr\", \"--hr\", nargs='+', help=\"List of HR ranges i.e. 0.5:2.0\")\n",
    "ap.add_argument(\"-c\", \"--countrate\", nargs='+', help=\"List of count rate ranges i.e. 2.0:2.0 3.0:5.0\", type=str)\n",
    "ap.add_argument(\"-i\", \"--input_file\", nargs='?', help=\"Input file with HR and count rates to split data\", type=str, default=\"segregation.txt\")\n",
    "args = ap.parse_args()\n",
    "\n",
    "\n",
    "if args.hr is None:\n",
    "    if os.path.isfile(args.input_file):\n",
    "        segregation_info = np.genfromtxt(args.input_file, names=True, dtype=(\"U22, U22\"), delimiter=\"\\t\", deletechars=\"\")\n",
    "        print(segregation_info)\n",
    "        hr_ranges = segregation_info[\"HR\"]\n",
    "        count_rate_ranges = segregation_info[\"countrates\"]\n",
    "else:\n",
    "    hr_ranges = args.hr\n",
    "    count_rate_ranges = args.countrate\n",
    "    if len(hr_ranges) != len(count_rate_ranges):\n",
    "        print(\"Error number of hr ranges has to be equal to countrate ranges\")\n",
    "        sys.exit()\n",
    "\n",
    "count_rate_file = \"PCCURVE.qdp\"\n",
    "hr_file = \"PCHR.qdp\"\n",
    "if os.path.isfile(count_rate_file) and os.path.isfile(hr_file):\n",
    "\n",
    "    data_count_rate = readPCCURVE(count_rate_file)\n",
    "    data_hr = readPCHR(hr_file)\n",
    "    print(\"Found %d swift observations in %s\" % (len(data_count_rate), count_rate_file))\n",
    "    print(\"Found %d swift observations in %s\" % (len(data_hr), hr_file))\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    # select only common obsid\n",
    "    common_obs, common_1, common_2 = np.intersect1d(data_count_rate[\"Time\"], data_hr[\"Time\"], return_indices=True)\n",
    "    print(\"Found %d common observations\" % len(common_obs))\n",
    "    data_count_rate = data_count_rate[common_1]\n",
    "    data_hr = data_hr[common_2]\n",
    "    chunk_counter = 1\n",
    "    colors = [\"orange\", \"green\", \"blue\", \"yellow\", \"olive\", \"purple\"]\n",
    "    #ax.errorbar(data_hr[\"HR\"], data_count_rate[\"Rate\"],\n",
    "    #            xerr=data_hr[\"HRerr\"], yerr=[-data_count_rate[\"Rateneg\"],\n",
    "    #            data_count_rate[\"Ratepos\"]], ls=\"None\", fmt=\"-\", color=\"black\", marker=\"+\")\n",
    "\n",
    "    string_out = \"#HR\\tcountrate\\tobsids\\n\"\n",
    "    for hr_range, count_range, color in zip(hr_ranges, count_rate_ranges, colors):\n",
    "        print(\"Filtering by %s HR values and %s count rate values\" % (hr_range, count_range))\n",
    "        string_out += \"%s\\t%s\\t\" % (hr_range, count_range)\n",
    "        hr_range = hr_range.split(\":\")\n",
    "        count_rate_range = count_range.split(\":\")\n",
    "        # filter by count rate\n",
    "        count_rate_chunk = data_count_rate[(data_count_rate['Rate'] >= float(count_rate_range[0])) & (data_count_rate['Rate'] <= float(count_rate_range[1]))]\n",
    "        # filter by hr\n",
    "        hr_chunk = data_hr[(data_hr['HR'] >= float(hr_range[0])) & (data_hr['HR'] <= float(hr_range[1]))]\n",
    "        common_chunk_obs, indexes_1, indexes_2 = np.intersect1d(hr_chunk[\"Time\"], count_rate_chunk[\"Time\"], return_indices=True)\n",
    "        final_hr = hr_chunk[indexes_1]\n",
    "        final_countrate = count_rate_chunk[indexes_2]\n",
    "        print(\"Obsids for chunk 1 (total %d/%d)\" % (len(common_chunk_obs), len(data_count_rate)))\n",
    "        obsstring = \"\"\n",
    "        for row in final_hr:\n",
    "            obs = str(row[\"Obsid\"])\n",
    "            print(obs)\n",
    "            obsstring += \"%s,\" % obs.split(\"::ObsID=\")[1]\n",
    "            string_out += \"%s,\" % obs.split(\"::ObsID=\")[1]\n",
    "        print(obsstring)\n",
    "        ax.errorbar(final_hr[\"HR\"], final_countrate[\"Rate\"],\n",
    "                    xerr=final_hr[\"HRerr\"], yerr=[-final_countrate[\"Rateneg\"],\n",
    "                    final_countrate[\"Ratepos\"]], ls=\"None\", fmt=\"-\", color=color, marker=\"+\")\n",
    "        chunk_counter += 1\n",
    "        string_out += \"\\n\"\n",
    "    file = open(\"segregation_out.txt\", \"w\")\n",
    "    file.write(string_out)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f11766-990b-4e81-913a-6e97dac33999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
